{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d69394d",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721683b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import matplotlib.pyplot as plt\n",
    "from yolov8.utils import xywh2xyxy, draw_detections, multiclass_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9815dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8:\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5):\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "\n",
    "        # Initialize model\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.detect_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=onnxruntime.get_available_providers())\n",
    "        # Get model info\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Perform inference on the image\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids = self.process_output(outputs)\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        self.img_height, self.img_width = image.shape[:2]\n",
    "\n",
    "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize input image\n",
    "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
    "\n",
    "        # Scale input pixel values to 0 to 1\n",
    "        input_img = input_img / 255.0\n",
    "        input_img = input_img.transpose(2, 0, 1)\n",
    "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_output(self, output):\n",
    "        predictions = np.squeeze(output[0]).T\n",
    "\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        # Get the class with the highest confidence\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = self.extract_boxes(predictions)\n",
    "\n",
    "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        # indices = nms(boxes, scores, self.iou_threshold)\n",
    "        indices = multiclass_nms(boxes, scores, class_ids, self.iou_threshold)\n",
    "\n",
    "        return boxes[indices], scores[indices], class_ids[indices]\n",
    "\n",
    "    def extract_boxes(self, predictions):\n",
    "        # Extract boxes from predictions\n",
    "        boxes = predictions[:, :4]\n",
    "\n",
    "        # Scale boxes to original image dimensions\n",
    "        boxes = self.rescale_boxes(boxes)\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def rescale_boxes(self, boxes):\n",
    "\n",
    "        # Rescale boxes to original image dimensions\n",
    "        input_shape = np.array([self.input_width, self.input_height, self.input_width, self.input_height])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([self.img_width, self.img_height, self.img_width, self.img_height])\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
    "\n",
    "        return draw_detections(image, self.boxes, self.scores,self.class_ids, mask_alpha)\n",
    "\n",
    "    def get_input_details(self):\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e489ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f75ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov8 import YOLOv8\n",
    "model_path = \"C:/Users/USER/runs/detect/train77/weights/best.onnx\"\n",
    "yolov8_detector = YOLOv8(model_path, conf_thres=0.5, iou_thres=0.3)\n",
    "path = os.getcwd()\n",
    "img = imread(os.path.join(os.path.join(os.path.join(path,\"img_data\"),\"All_img\"),\"00003.jpg\"))\n",
    "boxes, scores, class_ids = yolov8_detector(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba39704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] [0.7843468]\n"
     ]
    }
   ],
   "source": [
    "print(class_ids,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b25c73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_img = yolov8_detector.draw_detections(img)\n",
    "cv2.namedWindow(\"Detected Objects\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Detected Objects\", combined_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d01f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
